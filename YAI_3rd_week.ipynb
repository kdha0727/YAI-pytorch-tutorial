{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Term: YAI 2021 summer session\n",
    "\n",
    "Team Member: Dongha Kim, Jeongeun Lee, Junho Lee, Suyeong Choi."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LeNet-5 FashionMNIST Classification\n",
    "Implement\n",
    "* Set hyper parameters\n",
    "* Call dataset from torchvision & make dataloader\n",
    "* Build a LeNet-5\n",
    "* Instantiate LeNet & define loss function and optimizer\n",
    "* Training\n",
    "* Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Runtime Information>\n",
      "OS version: \t\tmacOS-11.5.1-arm64-arm-64bit\n",
      "Python version:\t\t3.8.10 | packaged by conda-forge\n",
      "Torch version:\t\t1.8.0\n",
      "Torch device:\t\tcpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from extensions.easyrun import runtime_info, dataset_info, Trainer  # type: ignore\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Environment check\n",
    "print(runtime_info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set hyper parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and Preprocess Dataset\n",
    "* Use Train Dataset with training and validating (5:1)\n",
    "* Use Test Dataset with testing after learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset Information>\n",
      "Train Dataset: \t\t50000\n",
      "Validation Dataset: \t10000\n",
      "Test Dataset: \t\t10000\n"
     ]
    }
   ],
   "source": [
    "# Set transform for preprocessing\n",
    "\n",
    "dataset_dir = 'data'\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dataset_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dataset_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(  # type: ignore\n",
    "    train_dataset, [50000, 10000])  # split - 5:1\n",
    "\n",
    "# Print Information\n",
    "\n",
    "print(dataset_info(train_dataset, val_dataset, test_dataset, loader=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DataLoader Information>\n",
      "Train Batch: \t\t781\n",
      "Validation Batch: \t156\n",
      "Test Batch: \t\t156\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(  # type: ignore\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(  # type: ignore\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(  # type: ignore\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# Print Information\n",
    "\n",
    "print(dataset_info(train_loader, val_loader, test_loader, loader=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a LeNet-5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(LeNet5,self).__init__()\n",
    "        self.feature_extractor: torch.nn.Module = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "            torch.nn.Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "            torch.nn.Conv2d(16, 120, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            torch.nn.Tanh(),\n",
    "        )\n",
    "        self.classifier: torch.nn.Module = torch.nn.Sequential(\n",
    "            torch.nn.Linear(120, 84),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(84, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(-1, 120)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train, Validate and Test\n",
    "Trainer Source:\n",
    "* https://github.com/kdha0727/Easyrun-Pytorch/blob/master/easyrun.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Start Learning> \t\t\t\tTotal 20 epochs\n",
      "\n",
      "Epoch 1\n",
      "[Train]\t Average loss: 0.63816, \t\tTotal accuracy: 76.53% \n",
      "[Eval]\t Average loss: 0.45017, \t\tTotal accuracy: 84.01%\n",
      "\n",
      "Epoch 2\n",
      "[Train]\t Average loss: 0.42638, \t\tTotal accuracy: 84.39% \n",
      "[Eval]\t Average loss: 0.40362, \t\tTotal accuracy: 85.49%\n",
      "\n",
      "Epoch 3\n",
      "[Train]\t Average loss: 0.37809, \t\tTotal accuracy: 86.01% \n",
      "[Eval]\t Average loss: 0.38107, \t\tTotal accuracy: 86.24%\n",
      "\n",
      "Epoch 4\n",
      "[Train]\t Average loss: 0.34346, \t\tTotal accuracy: 87.39% \n",
      "[Eval]\t Average loss: 0.35472, \t\tTotal accuracy: 87.11%\n",
      "\n",
      "Epoch 5\n",
      "[Train]\t Average loss: 0.32100, \t\tTotal accuracy: 88.14% \n",
      "[Eval]\t Average loss: 0.34431, \t\tTotal accuracy: 87.80%\n",
      "\n",
      "Epoch 6\n",
      "[Train]\t Average loss: 0.30079, \t\tTotal accuracy: 88.83% \n",
      "[Eval]\t Average loss: 0.33630, \t\tTotal accuracy: 87.99%\n",
      "\n",
      "Epoch 7\n",
      "[Train]\t Average loss: 0.28604, \t\tTotal accuracy: 89.36% \n",
      "[Eval]\t Average loss: 0.33043, \t\tTotal accuracy: 88.10%\n",
      "\n",
      "Epoch 8\n",
      "[Train]\t Average loss: 0.26914, \t\tTotal accuracy: 90.04% \n",
      "[Eval]\t Average loss: 0.32304, \t\tTotal accuracy: 88.50%\n",
      "\n",
      "Epoch 9\n",
      "[Train]\t Average loss: 0.25708, \t\tTotal accuracy: 90.43% \n",
      "[Eval]\t Average loss: 0.32667, \t\tTotal accuracy: 88.72%\n",
      "\n",
      "Epoch 10\n",
      "[Train]\t Average loss: 0.24508, \t\tTotal accuracy: 90.86% \n",
      "[Eval]\t Average loss: 0.31166, \t\tTotal accuracy: 88.96%\n",
      "\n",
      "Epoch 11\n",
      "[Train]\t Average loss: 0.23452, \t\tTotal accuracy: 91.34% \n",
      "[Eval]\t Average loss: 0.32886, \t\tTotal accuracy: 88.16%\n",
      "\n",
      "Epoch 12\n",
      "[Train]\t Average loss: 0.22389, \t\tTotal accuracy: 91.69% \n",
      "[Eval]\t Average loss: 0.31501, \t\tTotal accuracy: 89.18%\n",
      "\n",
      "Epoch 13\n",
      "[Train]\t Average loss: 0.21331, \t\tTotal accuracy: 92.03% \n",
      "[Eval]\t Average loss: 0.31055, \t\tTotal accuracy: 89.30%\n",
      "\n",
      "Epoch 14\n",
      "[Train]\t Average loss: 0.20436, \t\tTotal accuracy: 92.34% \n",
      "[Eval]\t Average loss: 0.31277, \t\tTotal accuracy: 89.07%\n",
      "\n",
      "Epoch 15\n",
      "[Train]\t Average loss: 0.19709, \t\tTotal accuracy: 92.60% \n",
      "[Eval]\t Average loss: 0.31334, \t\tTotal accuracy: 89.55%\n",
      "\n",
      "Epoch 16\n",
      "[Train]\t Average loss: 0.18666, \t\tTotal accuracy: 93.09% \n",
      "[Eval]\t Average loss: 0.31547, \t\tTotal accuracy: 89.26%\n",
      "\n",
      "Epoch 17\n",
      "[Train]\t Average loss: 0.18038, \t\tTotal accuracy: 93.35% \n",
      "[Eval]\t Average loss: 0.31301, \t\tTotal accuracy: 89.40%\n",
      "\n",
      "Epoch 18\n",
      "[Train]\t Average loss: 0.17027, \t\tTotal accuracy: 93.58% \n",
      "[Eval]\t Average loss: 0.32029, \t\tTotal accuracy: 89.03%\n",
      "\n",
      "Epoch 19\n",
      "[Train]\t Average loss: 0.16357, \t\tTotal accuracy: 93.91% \n",
      "[Eval]\t Average loss: 0.34018, \t\tTotal accuracy: 89.08%\n",
      "\n",
      "Epoch 20\n",
      "[Train]\t Average loss: 0.15677, \t\tTotal accuracy: 94.33% \n",
      "[Eval]\t Average loss: 0.32782, \t\tTotal accuracy: 89.13%\n",
      "\n",
      "<Stop Learning> \tLeast loss: 0.3105\tDuration: 3m 51.28s\n",
      "\n",
      "[Test]\t Average loss: 0.32188, \t\tTotal accuracy: 88.75%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "\n",
    "model = LeNet5()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "with Trainer(\n",
    "        model, 'CrossEntropyLoss', optimizer, num_epochs,\n",
    "        train_loader, val_loader, test_loader,\n",
    "        verbose=True, timer=True, snapshot_dir='.',\n",
    ") as trainer:\n",
    "    trainer.to(device)\n",
    "    trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-df61859e",
   "language": "python",
   "display_name": "PyCharm (YAI)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}