{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-VZ7UK9Op6x"
   },
   "source": [
    "Term: YAI 2021 summer session\n",
    "\n",
    "Team Member: Dongha Kim, Jeongeun Lee, Junho Lee, Suyeong Choi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ssH-DKB8Ihv0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1057c4730>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Import and prepare libraries\n",
    "#\n",
    "\n",
    "# Import numpy and pytorch\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "# Random seeding: it will all result accuracy values identical\n",
    "\n",
    "torch.manual_seed(77)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gzp8BcKErmnG"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Define Shortcut Functions\n",
    "#\n",
    "\n",
    "# Sigmoid: exp(x) / 1 + exp(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "  return torch.div(torch.tensor(1.0), torch.add(torch.tensor(1.0), torch.exp(torch.negative(x))))\n",
    "\n",
    "\n",
    "# Sigmoid derivative: y * (1 - y)\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "  return torch.mul(sigmoid(x), torch.subtract(torch.tensor(1.0), sigmoid(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "X6XRFOzKJHha"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Prepare dataset\n",
    "#\n",
    "\n",
    "# Use MNIST dataset\n",
    "# Download and process dataset, and transform from numpy array to tensor\n",
    "train_MNIST = datasets.MNIST(\"MNIST_data/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Make data loader from dataset\n",
    "# Since we will only train model, we can prepare data without splitting val/test set.\n",
    "# And we will make data without batching.\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_MNIST, shuffle=True, drop_last=True)  # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0rfQnmSuOlw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Model information**\n",
    "\n",
    "---\n",
    "\n",
    "The MLP has an input layer, one hidden layer, and one output layer.\n",
    "\n",
    "The input layer, the hidden layer, and the output layer has 784 nodes, 128 nodes, and 10 nodes, respectively.\n",
    "\n",
    "Used given sigmoid function as activation function.\n",
    "\n",
    "---\n",
    "\n",
    "Equation to implement forward pass: $(x = input, a_2 = prediction)$\n",
    "\n",
    "\n",
    "$$ z_1 = W_1 x + b_1 $$\n",
    "$$ a_1 = \\sigma(z_1) $$\n",
    "$$ z_2 = W_2 a_1 + b_2 $$\n",
    "$$ a_2 = \\sigma(z_2) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#\n",
    "# Set hyper-parameters and initialize model params\n",
    "#\n",
    "\n",
    "# Configure layer\n",
    "# In this task, we use two-layer-net\n",
    "D_in, H, D_out = 784, 128, 10\n",
    "\n",
    "# Learning rate for SGD\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Epochs\n",
    "epochs = 5\n",
    "\n",
    "# Initialize model-params, with normalizing (multiply 1 / sqrt(num_layer))\n",
    "\n",
    "# A weight and a bias for input nodes\n",
    "w1 = Variable(torch.randn(D_in, H, dtype=torch.float32, requires_grad=True)) * np.sqrt(1. / D_in)\n",
    "b1 = Variable(torch.randn(1, H, dtype=torch.float32, requires_grad=True)) * np.sqrt(1. / D_in)\n",
    "\n",
    "# A weight and a bias for hidden nodes\n",
    "w2 = Variable(torch.randn(H, D_out, dtype=torch.float32, requires_grad=True)) * np.sqrt(1. / H)\n",
    "b2 = Variable(torch.randn(1, D_out, dtype=torch.float32, requires_grad=True)) * np.sqrt(1. / H)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-z6SRbEivhpq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0/60000\n",
      "Epoch 1: 10000/60000\n",
      "Epoch 1: 20000/60000\n",
      "Epoch 1: 30000/60000\n",
      "Epoch 1: 40000/60000\n",
      "Epoch 1: 50000/60000\n",
      "Epoch 1, Accuracy: 0.896\n",
      "Epoch 2: 0/60000\n",
      "Epoch 2: 10000/60000\n",
      "Epoch 2: 20000/60000\n",
      "Epoch 2: 30000/60000\n",
      "Epoch 2: 40000/60000\n",
      "Epoch 2: 50000/60000\n",
      "Epoch 2, Accuracy: 0.948\n",
      "Epoch 3: 0/60000\n",
      "Epoch 3: 10000/60000\n",
      "Epoch 3: 20000/60000\n",
      "Epoch 3: 30000/60000\n",
      "Epoch 3: 40000/60000\n",
      "Epoch 3: 50000/60000\n",
      "Epoch 3, Accuracy: 0.961\n",
      "Epoch 4: 0/60000\n",
      "Epoch 4: 10000/60000\n",
      "Epoch 4: 20000/60000\n",
      "Epoch 4: 30000/60000\n",
      "Epoch 4: 40000/60000\n",
      "Epoch 4: 50000/60000\n",
      "Epoch 4, Accuracy: 0.969\n",
      "Epoch 5: 0/60000\n",
      "Epoch 5: 10000/60000\n",
      "Epoch 5: 20000/60000\n",
      "Epoch 5: 30000/60000\n",
      "Epoch 5: 40000/60000\n",
      "Epoch 5: 50000/60000\n",
      "Epoch 5, Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Start Training\n",
    "#\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  # Counter for measuring train accuracy\n",
    "  corrects = 0\n",
    "\n",
    "  # For each data,\n",
    "  for i, (x, y) in enumerate(train_loader):\n",
    "\n",
    "    # Batch size = 1 (without batching)\n",
    "    x = x.reshape((1,-1))\n",
    "\n",
    "    # Convert label to one-hot vector\n",
    "    y_onehot = torch.zeros((1,10))\n",
    "    y_onehot[0,y] += 1\n",
    "\n",
    "    #\n",
    "    # forward pass\n",
    "    #\n",
    "\n",
    "    # z1 = x @ w1 + b1\n",
    "    z1 = torch.add(torch.mm(x, w1), b1)\n",
    "    a1 = sigmoid(z1)\n",
    "    # z2 = a1 @ w2 + b2\n",
    "    z2 = torch.add(torch.mm(a1, w2), b2)\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    diff = a2 - y_onehot\n",
    "\n",
    "    #\n",
    "    # backward pass\n",
    "    #\n",
    "\n",
    "    # dE/dz2 = diff * da2/dz2\n",
    "    d_z2 = torch.mul(diff, sigmoid_prime(z2))\n",
    "    # dE/db2 = dE/dz2 의 element sum\n",
    "    d_b2 = sum(d_z2)\n",
    "    # dE/dw2 = a1_transpose @ dE/dz2\n",
    "    d_w2 = torch.mm(torch.transpose(a1, 0, 1), d_z2)\n",
    "\n",
    "    # dE/da1 = dE/dz2 @ w2_transpose\n",
    "    d_a1 = torch.mm(d_z2, torch.transpose(w2, 0, 1))\n",
    "    # dE/dz1 = dE/da1 * da1/dz1\n",
    "    d_z1 = torch.mul(d_a1, sigmoid_prime(z1))\n",
    "    # dE/db1 = dE/dz1 의 element sum\n",
    "    d_b1 = sum(d_z1)\n",
    "    # dE/dw1 = x_transpose @ dE/dz1\n",
    "    d_w1 = torch.mm(torch.transpose(x, 0, 1), d_z1)\n",
    "\n",
    "    #\n",
    "    # optimize weight by Gradient Descent\n",
    "    #\n",
    "\n",
    "    w1 -= d_w1 * learning_rate\n",
    "    b1 -= d_b1 * learning_rate\n",
    "    w2 -= d_w2 * learning_rate\n",
    "    b2 -= d_b2 * learning_rate\n",
    "\n",
    "    # Update counter\n",
    "    if torch.argmax(a2) == y:\n",
    "      corrects += 1\n",
    "\n",
    "    # Report procedure\n",
    "    if i % 10000 == 0:\n",
    "      print(\"\\rEpoch {}: {}/{}\".format(epoch+1, i, len(train_MNIST)), end='')\n",
    "\n",
    "  # Report accuracy per each epoch\n",
    "  print(\"Epoch {}, Accuracy: {:.3f}\".format(epoch+1, corrects/len(train_MNIST))) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "YAI_1st_week.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}